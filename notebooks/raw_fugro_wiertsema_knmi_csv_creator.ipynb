{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f57882b6",
   "metadata": {},
   "source": [
    "# Setting up the notebook and realtive paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover repo root and read all CSV files from the per-series folders\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Find repo root (stop at folder containing pyproject.toml or .git)\n",
    "repo_root = Path.cwd()\n",
    "for candidate in [repo_root] + list(repo_root.parents):\n",
    "    if (candidate / 'pyproject.toml').exists() or (candidate / '.git').exists():\n",
    "        repo_root = candidate\n",
    "        break\n",
    "print('Repo root:', repo_root)\n",
    "\n",
    "wiertsema_dir = repo_root / 'output_data' / 'only_csv_wiertsema'\n",
    "fugro_dir = repo_root / 'output_data' / 'only_csv_fugro'\n",
    "# Directory containing meteorological/stressor CSVs\n",
    "stressor_dir = repo_root / 'input_stressors'\n",
    "# Explicit stressor file paths used elsewhere in notebooks\n",
    "precip_path = stressor_dir / 'Neerslag_2021_2025.csv'\n",
    "evap_path = stressor_dir / 'Verdamping_2021_2025.csv'\n",
    "\n",
    "out_fig = repo_root / 'output_data' / 'figures'\n",
    "out_fig.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('wiertsema_dir ->', wiertsema_dir)\n",
    "print('fugro_dir    ->', fugro_dir)\n",
    "print('precip_path ->', precip_path)\n",
    "print('evap_path  ->', evap_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d57f27",
   "metadata": {},
   "source": [
    "# Loading in the precipitation and evap file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4610110",
   "metadata": {},
   "source": [
    "Based on data with the \".\" seperator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2180e6",
   "metadata": {},
   "source": [
    "For different dataset based on hourly data with the \";\" and \",\" seperators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56120795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prec = (\n",
    "    pd.read_csv(\n",
    "        precip_path,\n",
    "        sep=\";\",              # <-- semicolon-delimited file\n",
    "        decimal=\",\",          # <-- comma decimals (e.g., 0,05)\n",
    "        index_col=0,\n",
    "        parse_dates=[0],      # parse the first column as datetime\n",
    "        dayfirst=True,        # because '1-01-21 0:00' is D-M-YY\n",
    "        # date_format=\"%d-%m-%y %H:%M\",  # (optional) faster & stricter\n",
    "        encoding=\"utf-8-sig\",\n",
    "        encoding_errors=\"replace\",\n",
    "    )\n",
    "    if precip_path.exists() else None\n",
    ")\n",
    "\n",
    "df_prec_mm = df_prec / 10\n",
    "\n",
    "df_evap = (\n",
    "    pd.read_csv(\n",
    "        evap_path,\n",
    "        sep=\";\",              # <-- semicolon-delimited file\n",
    "        decimal=\",\",          # <-- comma decimals (e.g., 0,05)\n",
    "        index_col=0,\n",
    "        parse_dates=[0],      # parse the first column as datetime\n",
    "        dayfirst=True,        # because '1-01-21 0:00' is D-M-YY\n",
    "        # date_format=\"%d-%m-%y %H:%M\",  # (optional) faster & stricter\n",
    "        encoding=\"utf-8-sig\",\n",
    "        encoding_errors=\"replace\",\n",
    "    )\n",
    "    if precip_path.exists() else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestand is van het KNMI, neerslag in 0.1 mm dus omzetten naar mm\n",
    "df_prec_mm = df_prec / 10\n",
    "df_prec_mm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189252fc",
   "metadata": {},
   "source": [
    "# Function to create the .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091fadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def process_measurement_csv(\n",
    "    filepath: Path,\n",
    "    df_prec_mm: pd.DataFrame,\n",
    "    df_evap: pd.DataFrame,\n",
    "    output_dir: Path,\n",
    "    output_suffix=\"_processed.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a groundwater head CSV file: aligns with precipitation and evapotranspiration,\n",
    "    calculates recharge and head change (head_t1), and writes selected columns to a new CSV.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (Path): Path to the input CSV.\n",
    "        df_prec_mm (pd.DataFrame): Precipitation data (with datetime index).\n",
    "        df_evap (pd.DataFrame): Evapotranspiration data (with datetime index).\n",
    "        output_dir (Path): Directory to save processed CSVs.\n",
    "        output_suffix (str): Suffix added to the output filename.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and parse input CSV\n",
    "        head_df = pd.read_csv(\n",
    "            filepath,\n",
    "            index_col=0,\n",
    "            parse_dates=True,\n",
    "            encoding=\"utf-8-sig\",\n",
    "            encoding_errors=\"replace\"\n",
    "        )\n",
    "\n",
    "        # Drop duplicate timestamps, keeping the last\n",
    "        head_df = head_df[~head_df.index.duplicated(keep=\"last\")]\n",
    "\n",
    "        # Ensure all values are numeric\n",
    "        head_df = head_df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "        # Crop dataframe from first to last valid head entry\n",
    "        first_valid = head_df.iloc[:, 0].first_valid_index()\n",
    "        last_valid = head_df.iloc[:, 0].last_valid_index()\n",
    "        if first_valid is not None and last_valid is not None:\n",
    "            head_df = head_df.loc[first_valid:last_valid]\n",
    "\n",
    "        # Align to reference index\n",
    "        ref_index = df_evap.index\n",
    "        head_df = head_df.reindex(ref_index)\n",
    "\n",
    "        # Merge with precipitation and evapotranspiration\n",
    "        merged = pd.concat([\n",
    "            df_prec_mm.reindex(ref_index),\n",
    "            df_evap.reindex(ref_index),\n",
    "            head_df\n",
    "        ], axis=1)\n",
    "        \n",
    "        # Find the head column (3rd column before renaming)\n",
    "        head_col = merged.columns[2] if merged.shape[1] > 2 else None\n",
    "        \n",
    "        # Crop from first non-NaN head entry onward\n",
    "        if head_col is not None:\n",
    "            first_valid_head = merged[head_col].first_valid_index()\n",
    "            if first_valid_head is not None:\n",
    "                merged = merged.loc[first_valid_head:]\n",
    "\n",
    "        # Rename the head column (3rd column) to \"head\"\n",
    "        if merged.shape[1] > 2:\n",
    "            merged = merged.rename(columns={merged.columns[2]: \"head\"})\n",
    "\n",
    "        # Ensure required columns exist and are numeric\n",
    "        for col in [\"Precipitation\", \"Evapotranspiration\", \"head\"]:\n",
    "            if col in merged.columns:\n",
    "                merged[col] = pd.to_numeric(merged[col], errors=\"coerce\")\n",
    "            else:\n",
    "                raise ValueError(f\"Missing column: {col}\")\n",
    "\n",
    "        # Compute recharge and head_t1\n",
    "        merged[\"recharge\"] = merged[\"Precipitation\"] - merged[\"Evapotranspiration\"]\n",
    "        merged[\"head_t1\"] = merged[\"head\"].diff()\n",
    "\n",
    "        # Select and reorder columns\n",
    "        output_df = merged[[\"head\", \"Precipitation\", \"Evapotranspiration\", \"recharge\", \"head_t1\"]]\n",
    "\n",
    "        # Crop from first non-NaN head entry onward\n",
    "        first_valid_head = output_df[\"head\"].first_valid_index()\n",
    "        if first_valid_head is not None:\n",
    "            output_df = output_df.loc[first_valid_head:]\n",
    "\n",
    "        # Drop rows with NaNs in all selected columns\n",
    "        output_df = output_df.dropna(how=\"all\")\n",
    "\n",
    "        # Ensure output directory exists\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Write to CSV\n",
    "        output_file = output_dir / f\"{filepath.stem}{output_suffix}\"\n",
    "        output_df.index.name = \"timestamp\"\n",
    "        output_df.to_csv(output_file, encoding=\"utf-8-sig\")\n",
    "\n",
    "        print(f\"✓ Processed: {filepath.name} → {output_file.name}\")\n",
    "        return output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing {filepath.name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55819225",
   "metadata": {},
   "source": [
    "# Use the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ddd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "input_dir = repo_root / \"output_data\" / \"only_csv_fugro\"\n",
    "output_dir = repo_root / \"output_data\" / \"hourly_csv_fugro_knmi_unfiltered\"\n",
    "\n",
    "# Get all CSV files\n",
    "csv_files = sorted(input_dir.glob(\"*.csv\"))\n",
    "print(f\"Found {len(csv_files)} CSV files in {input_dir.name}\")\n",
    "\n",
    "# Process each file\n",
    "for i, file_path in enumerate(csv_files, start=1):\n",
    "    print(f\"[{i}/{len(csv_files)}] Processing: {file_path.name}\")\n",
    "    process_measurement_csv(\n",
    "        filepath=file_path,\n",
    "        df_prec_mm=df_prec_mm,\n",
    "        df_evap=df_evap,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "\n",
    "print(f\"\\n✓ All processed CSVs saved to: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-validation-py3.12 (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
